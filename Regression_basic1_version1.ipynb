{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回帰分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章では回帰分析の種類とその使い方に関して説明する。\n",
    "まず、回帰分析とは、例えば「9月1日のアイスコーヒーの売上数を、8月の各日の気温とアイスコーヒーの売れ行きから予想する」のように、関係する要素をもとに、実数値を予測することである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず最初に、以下二つの項で利用する用語について簡潔に解説しておく。\n",
    "\n",
    "- 目的変数：予測の対象となる変数。上の例で言う「9月1日のアイスコーヒーの売上数」である。\n",
    "- 説明変数：物事の原因となっている変数。目的変数を説明する変数。上の例でいう「8月の各日の気温」である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単回帰分析\n",
    "\n",
    "単回帰分析とは、一つの目的変数$y$に対して、一つの説明変数$x$を用いてその関係を表すこと。一般に$y=ax+b$の形で表される。\n",
    "ここで、$y$は目的変数、$x$は説明変数、$a$は回帰係数、$b$は切片を表す。\n",
    "単回帰分析の目標はこの$a$と$b$を求めることである。\n",
    "\n",
    "今回はPythonの機械学習ライブラリである`Scikit-learn`を用いた手法を紹介する。回帰直線を求める際はこの`Scikit-learn`を用いるのが一般的である。\n",
    "\n",
    "データセットを示したのちに、回帰分析に関わる数値やグラフを順を追って求めていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはデータの読み込みを行う。\n",
    "\n",
    "今回使用するデータは、`Scikit-learn`に同梱されているトイ・データセットの中で、Bostonの住宅価格に関するデータ、**load_boston**である。\n",
    "また、この**load_boston**は、13の説明変数、1の目的変数からなる、サンプル数506のデータである。13の説明変数には犯罪発生率、不動産税率、生徒と教師の割合など、住宅価格に関係しうるデータが連なっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、`pandas`をインポートしたのち、複数ある説明変数と、目的変数をデータフレームに保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasライブラリを pd という名前で使えるようにする\n",
    "# pd と省略形にするのが通例である\n",
    "import pandas as pd\n",
    "\n",
    "boston_df = pd.DataFrame(boston.data, columns = boston.feature_names) #説明変数\n",
    "boston_df['MEDV'] = boston.target #目的変数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現時点でのデータの先頭付近の要素を見ておく。データフレームの最初の行を見る場合は下記の通り head() を用いるが、\n",
    "最後の行を見たい場合は tail() を用いる。\n",
    "\n",
    "13の説明変数と1の目的変数があることが分かる。また、同様にtail()を用いることでサンプルデータの数を確認することも可能である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの最初を見る\n",
    "boston_df.head()  \n",
    "\n",
    "#データの最後を見る\n",
    "#boston_df.tail()\n",
    "\n",
    "#データ全てを見る\n",
    "#diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、今回の単回帰分析における説明変数と目的変数を定義する。本講義では説明変数を**低所得者の割合（LSTAT）**、目的変数を**ボストンの住宅価格の中央値（MEDV）**とした。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston_df[['LSTAT']]  #xに説明変数\n",
    "y = boston_df[['MEDV']]  #yに目的変数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでこれら二つのデータを図に表してみる。下で用いている、`matplotlib.pyplot`、`seaborn`はいずれもpythonの描画のためのライブラリである。\n",
    "上記のxを横軸に、yを縦軸にして、点の描画タイプを'o'としたのち、プロットしている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "#点のプロット\n",
    "plt.plot(x, y, 'o')\n",
    "\n",
    "#軸ラベル\n",
    "plt.xlabel('[LSTAT]')\n",
    "plt.ylabel('[MEDV]')\n",
    "\n",
    "#最終的な描画\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは本題の単回帰分析を行う。scikit-learnを用いた場合、単回帰分析自体は最初の3行で終えており、以降の4行は回帰に関する様々な数値、数式を導出するものとなっている。\n",
    "\n",
    "ここで出てきた決定係数$R^2$は、適合度（説明変数がどれほど目的変数を説明しているか）を表しており、0に近ければ適合度が低く、1に近ければ適合度が高いといえる。また、この決定係数の大小に明確な基準はなく、0.5以上から適合度が高いとすることが多い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#この2行で回帰分析を行う\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(x, y)\n",
    "\n",
    "#以降回帰分析で重要な数値群の導出\n",
    "print('回帰変数 w1: %.3f' %model_lr.coef_)\n",
    "print('切片 w2: %.3f' %model_lr.intercept_)\n",
    "print('回帰直線 y= %.3fx + %.3f' % (model_lr.coef_ , model_lr.intercept_))\n",
    "print('決定係数 R^2： ', model_lr.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "決定係数が0.5以上であることから、適合度はそれなりに高いことがわかった。\n",
    "\n",
    "最後にこの直線をグラフ上に描画してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#点のプロット\n",
    "plt.plot(x, y, 'o')\n",
    "\n",
    "#回帰直線の描画\n",
    "plt.plot(x, model_lr.predict(x), linestyle=\"solid\")\n",
    "\n",
    "#軸ラベル\n",
    "plt.xlabel('% lower status of the population')\n",
    "plt.ylabel('Median value of owner-occupied homes in $1000\\'s')\n",
    "\n",
    "#最終的な描画\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフ図を見るとわかるように、目的変数と説明変数の間には負の相関が見て取れる。\n",
    "また、低所得者の割合が少ないほど、住宅価格が高い傾向にあるのがわかる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=orange>【練習１】</font> \n",
    "上の説明においてboston_df.head()でデータの先頭を見た際に分かる通り、説明変数には平均部屋数（RM）、犯罪発生率（CRIM）がある。これらの各説明変数と、目的変数(MEDV)の間で単回帰分析を行い、\n",
    "\n",
    "(1)グラフ上にデータの散布と回帰直線を示せ。\n",
    "\n",
    "(2)決定係数をそれぞれの場合で調べ、適合度の高低を判別せよ。ただし、適合度に関する$R^2$の基準値は0.5とする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重回帰分析\n",
    "\n",
    "重回帰分析とは、一つの目的変数$y$に対して、複数の説明変数$x_{1},x_{2}\\cdots,x_{n}$を用いてその関係を表すこと。一般に$y=a_{1}x_{1}+a_{2}x_{2}+\\cdots+a_{n}x_{n}+b$の形で表される。\n",
    "  \n",
    "  例：ある店の駅からの距離、客席数、クレーム数（説明変数）と顧客満足度（目的変数）\n",
    "\n",
    "重回帰分析で気をつけるポイント\n",
    "\n",
    "- 入力変数に対する係数の信頼区間\n",
    "  - t値・p値\n",
    "- 多重線形性\n",
    "\n",
    "\n",
    "ここから実際にデータを扱って例を示してみる。流れとしては基本的には単回帰分析と同様である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "まずデータセットを示す。今回は`Scikit-learn`に同梱されているトイ・データセット（Toy Dataset）を用いる。\n",
    "\n",
    "今回使用するデータは、トイ・データセットの中で、糖尿病のに関するデータ、**load_diabetes**である。\n",
    "この**load_diabetes**は、10の説明変数、1の目的変数からなる、サンプル数442のデータである。\n",
    "\n",
    "また、これらのデータは説明変数age,sex,bmi,bp,s1,s2,s3,s4,s5,s6と目的変数targetによって構成され、s1-s6はコレステロール値や血糖値などを示す。これらの値は不明確である可能性との記載があり、厳密な値ではない恐れがある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単回帰分析と同様に、説明変数、目的変数をデータフレームに保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数の保存\n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names) \n",
    "\n",
    "#目的変数の保存\n",
    "diabetes_df['target'] = diabetes.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの確認をしよう。最右列に目的変数のtarget列があるのが確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの最初を見る\n",
    "diabetes_df.head()\n",
    "\n",
    "#データの最後を見る\n",
    "#diabetes_df.tail()\n",
    "\n",
    "#データ全てを見る\n",
    "#diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、今回の重回帰分析における説明変数と目的変数を定義する。本講義の例では複数ある説明変数のうち、bmi、bp、s1の3つを説明変数として取り上げる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = diabetes_df[['bmi','bp','s1']]  #xに説明変数\n",
    "y = diabetes_df[['target']]  #yに目的変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#この2行で回帰分析を行う\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単回帰分析と同様に回帰分析に重要な値を求めていく。\n",
    "\n",
    "決定係数に注目すると、値が0.5より小さくなっており、適合度が低いと見て取れる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#回帰変数\n",
    "print('回帰変数： ',model_lr.coef_)\n",
    "#切片\n",
    "print('切片： ',model_lr.intercept_)\n",
    "#決定係数\n",
    "print('決定係数 R^2： ', model_lr.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これはこれで正しい結果が出た。しかし、回帰変数の値が大きく離れている。この理由として挙げられるのが、説明変数の単位が異なるため、同じ土俵で比較ができないことにある。これを解決するのが**データの正規化(標準化)**である。次はデータを正規化した後の重回帰分析について見ていこう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**正規化**とは、データの平均を0、分散を1に揃えるように処理することである。これをすることで、説明変数の尺度を揃え、どの説明変数が大きな影響を目的変数に与えているかを判別することができる。\n",
    "\n",
    "それでは実際に正規化からやってみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正規化には一般的に複数のやり方があるが、今回は`scikit-learn`を用いたもので行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit-learn内のStandardScalerを用いたい\n",
    "from sklearn import preprocessing\n",
    "\n",
    "sscaler = preprocessing.StandardScaler()\n",
    "\n",
    "#説明変数の正規化\n",
    "sscaler.fit(x)\n",
    "xss = sscaler.transform(x) \n",
    "\n",
    "#目的変数の正規化\n",
    "sscaler.fit(y)\n",
    "yss = sscaler.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理で正規化が終わったので、この後は通常通りに重回帰分析を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#回帰分析\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(xss, yss)\n",
    "\n",
    "\n",
    "#正規化後の回帰変数\n",
    "print('回帰変数: ',model_lr.coef_)\n",
    "#正規化後の切片\n",
    "print('切片: ',model_lr.intercept_)\n",
    "#正規化後の決定係数\n",
    "print('決定係数 R^2： ', model_lr.score(xss, yss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの処理を施す前の結果と比べてみても、回帰変数の値が小さくなり、切片も0と見做せるほど小さくなった。ただ、これによって重回帰分析の結果が非常に見やすくなったものの、解析前にデータをいじってしまっているので、実際に数値予測をする際には元に戻す必要がある。\n",
    "\n",
    "元に戻す方法も実は簡単で、scikit-learnの正規化の逆変換を施す`inverse_tranceform`を用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの前処理を重回帰分析後に元に戻す\n",
    "sscaler.inverse_transform(model_lr.predict(xss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 入力変数に対する係数の信頼区間\n",
    "  - t値・p値\n",
    "    - t値:t検定による結果の妥当性の大きさ、すなわち説明変数が目的変数に与える影響の大きさを表す。\n",
    "    - p値:有意確率のこと。説明変数が目的変数と関係性があるか否かの判断に用いる。t値が起こる累積確率。\n",
    "- 多重線形性 : ある説明変数同士の相関が高い時、重回帰分析の結果が不安定になること。これを防ぐために、相関が高い二つ以上の説明変数は使わないことが挙げられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t値とp値は回帰分析の結果から計算していく方法もあるが、`statsmodels`を利用することですぐに求まるので、今回は部分的に用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statsmodelsは一般的にsmと省略することが多い\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#回帰分析\n",
    "model_lr2 = sm.OLS(y, sm.add_constant(x))\n",
    "\n",
    "# モデルの作成\n",
    "results = model_lr2.fit()\n",
    "\n",
    "#結果の詳細を表示\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力されたサマリーの中で**tと書かれているものがt値**、**pと書かれているものがp値**を表す。記載されている全ての項目を説明することはしないが、このサマリーの中には上で求めた決定係数の出力等もなされているので、興味がある学生は調べてみるとよい。\n",
    "\n",
    "一般的に、「**t値の絶対値が2より小さい場合にはその説明変数は目的変数に影響を与えない**」とすることが多い。このサマリーの値をみると分かるように、bmi、bpは目的変数に影響を与えているが、s1は影響を与えないことが分かる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=orange>【練習2】</font> \n",
    "説明変数をload_diabetes内のs2,s3,s4,s5とし、重回帰分析をおこなった際の決定係数を求めて適合度を評価せよ。\n",
    "\n",
    "また、t値を調べてみることで、s2,s3,s4,s5のうちどの項目が糖尿病の進行度に影響を与えているかを評価せよ。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
